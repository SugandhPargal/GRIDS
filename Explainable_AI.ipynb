{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ieKt2n-gAim"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from sklearn import tree\n",
        "data = pd.read_csv('D1_Speed_Profile.csv')\n",
        "df = pd.DataFrame(data, columns = data.columns)\n",
        "\n",
        "df.shape\n",
        "df = df.sample(frac = 1)\n",
        "\n",
        "x = df.drop(columns = [\"Filename\",\"Rating\"])\n",
        "#print(x[0:5])\n",
        "y = df[\"Rating\"]#save the feature name and target variables\n",
        "feature_names = x.columns\n",
        "\n",
        "labels = y.unique()#split the dataset\n",
        "le = LabelEncoder()\n",
        "le.fit(y.astype(str))\n",
        "y = le.transform(y.astype(str))\n",
        "\n",
        "X_train, test_x, y_train, test_lab = train_test_split(x,y,\n",
        "                                                 test_size = 0.3,\n",
        "                                                 random_state = 42)\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "#dict(zip(unique, counts))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a RF Classifier\n",
        "clf=RandomForestClassifier(n_estimators=10, \n",
        "                            max_depth=3,\n",
        "                            max_features='auto',\n",
        "                            bootstrap=True, \n",
        "                            n_jobs=-1, \n",
        "                            random_state=0)"
      ],
      "metadata": {
        "id": "wIXTKGGigKW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "clf.fit(X_train,y_train)\n",
        "spare_cn=str(labels)\n",
        "test_labels= str(y)\n",
        "print(spare_cn)\n",
        "print(np.unique(y))"
      ],
      "metadata": {
        "id": "5gcGS-jcgLVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred = clf.predict(X_train)\n",
        "feature_imp = pd.Series(clf.feature_importances_,index=feature_names).sort_values(ascending=False)\n",
        "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Features')\n",
        "plt.title(\"Visualizing Important Features\")\n",
        "plt.rcParams[\"figure.figsize\"] = (7,10)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "for i,v in enumerate(feature_imp):\n",
        "\tprint('Feature: %s, Score: %.5f' % (feature_imp.index[i],v))"
      ],
      "metadata": {
        "id": "76b44rpQgND-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n",
        "import shap"
      ],
      "metadata": {
        "id": "ido176RngQ8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_importance = X_train ######## test set passed, can be passed training set as well\n",
        "\n",
        "# Explain model predictions using shap library:\n",
        "explainer = shap.TreeExplainer(clf) ###### lgb_model is the fitted model\n",
        "shap_values = explainer.shap_values(X_importance)\n",
        "shap.summary_plot(shap_values, X_importance)\n",
        "\n",
        "importance_df = pd.DataFrame(index=[X_importance.columns.tolist()])\n",
        "#importance_df = pd.DataFrame([X_importance.columns.tolist()]).T\n",
        "#importance_df.columns = ['column_name']\n",
        "print(importance_df)\n",
        "for i in np.unique(y):\n",
        "  shap_sum = np.abs(shap_values[i]).mean(axis=0)\n",
        "  shap_sum= shap_sum.astype('float')\n",
        "  importance_df[i] = shap_sum.tolist()\n",
        "  \n",
        "\n",
        "\n",
        "importance_df = importance_df.sort_values(0, ascending=False)\n",
        "result = importance_df.idxmax(axis=1)\n",
        "importance_df\n",
        "importance_df.head(5)\n",
        "print(result)\n",
        "data_top = importance_df.head(5) \n",
        "important_fetures= data_top.index.tolist()"
      ],
      "metadata": {
        "id": "ldl8XINFgS5H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}